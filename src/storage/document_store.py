"""
ğŸ“š Document Store pro uklÃ¡dÃ¡nÃ­ a sprÃ¡vu dokumentÅ¯
Poskytuje jednotnÃ© rozhranÃ­ pro uklÃ¡dÃ¡nÃ­ a vyhledÃ¡vÃ¡nÃ­ dokumentÅ¯
"""

import asyncio
import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path
import hashlib
import uuid


class DocumentStore:
    """
    ğŸ“„ SprÃ¡vce dokumentÅ¯ pro autonomnÃ­ agenta

    Poskytuje funkcionalitu pro uklÃ¡dÃ¡nÃ­, vyhledÃ¡vÃ¡nÃ­ a sprÃ¡vu
    dokumentÅ¯ zÃ­skanÃ½ch bÄ›hem vÃ½zkumnÃ©ho procesu.
    """

    def __init__(self, storage_path: str = "data/documents"):
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)

        # In-memory index pro rychlÃ© vyhledÃ¡vÃ¡nÃ­
        self.documents_index: Dict[str, Dict[str, Any]] = {}
        self.metadata_file = self.storage_path / "index.json"

        # NaÄtenÃ­ existujÃ­cÃ­ho indexu
        self._load_index()

    async def store_document(self, document: Dict[str, Any]) -> str:
        """
        UloÅ¾Ã­ dokument do store

        Args:
            document: Dictionary s dokumentem (musÃ­ obsahovat 'content')

        Returns:
            str: UnikÃ¡tnÃ­ ID dokumentu
        """
        try:
            # GenerovÃ¡nÃ­ ID
            doc_id = str(uuid.uuid4())

            # PÅ™Ã­prava metadat
            metadata = {
                "id": doc_id,
                "url": document.get("url", ""),
                "title": document.get("title", ""),
                "content_hash": self._calculate_hash(document.get("content", "")),
                "content_length": len(document.get("content", "")),
                "timestamp": (
                    document.get("timestamp", datetime.now()).isoformat()
                    if isinstance(document.get("timestamp"), datetime)
                    else document.get("timestamp", datetime.now().isoformat())
                ),
                "source": document.get("source", "unknown"),
                "content_type": document.get("content_type", "text/plain"),
                "credibility_score": document.get("credibility_score", 0.0),
                "entities": document.get("entities", []),
                "patterns": document.get("patterns", []),
            }

            # UloÅ¾enÃ­ obsahu do souboru
            content_file = self.storage_path / f"{doc_id}.txt"
            with open(content_file, "w", encoding="utf-8") as f:
                f.write(document.get("content", ""))

            # UloÅ¾enÃ­ metadat do indexu
            self.documents_index[doc_id] = metadata

            # Persist index
            await self._save_index()

            logging.info(f"ğŸ“š Dokument uloÅ¾en: {doc_id}")
            return doc_id

        except Exception as e:
            logging.error(f"âŒ Chyba pÅ™i uklÃ¡dÃ¡nÃ­ dokumentu: {e}")
            raise

    async def get_document(self, doc_id: str) -> Optional[Dict[str, Any]]:
        """
        ZÃ­skÃ¡ dokument podle ID

        Args:
            doc_id: ID dokumentu

        Returns:
            Dict s dokumentem nebo None
        """
        try:
            if doc_id not in self.documents_index:
                return None

            metadata = self.documents_index[doc_id].copy()

            # NaÄtenÃ­ obsahu
            content_file = self.storage_path / f"{doc_id}.txt"
            if content_file.exists():
                with open(content_file, "r", encoding="utf-8") as f:
                    metadata["content"] = f.read()
            else:
                metadata["content"] = ""

            return metadata

        except Exception as e:
            logging.error(f"âŒ Chyba pÅ™i naÄÃ­tÃ¡nÃ­ dokumentu {doc_id}: {e}")
            return None

    async def search_documents(self, query: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        VyhledÃ¡ dokumenty podle query

        Args:
            query: VyhledÃ¡vacÃ­ dotaz
            limit: Max poÄet vÃ½sledkÅ¯

        Returns:
            List dokumentÅ¯ seÅ™azenÃ½ch podle relevance
        """
        try:
            results = []
            query_lower = query.lower()

            for doc_id, metadata in self.documents_index.items():
                score = 0.0

                # VyhledÃ¡vÃ¡nÃ­ v title
                title = metadata.get("title", "").lower()
                if query_lower in title:
                    score += 2.0

                # VyhledÃ¡vÃ¡nÃ­ v URL
                url = metadata.get("url", "").lower()
                if query_lower in url:
                    score += 1.0

                # VyhledÃ¡vÃ¡nÃ­ v source
                source = metadata.get("source", "").lower()
                if query_lower in source:
                    score += 0.5

                # Bonus za vysokou dÅ¯vÄ›ryhodnost
                credibility = metadata.get("credibility_score", 0.0)
                score += credibility * 0.5

                if score > 0:
                    result = metadata.copy()
                    result["search_score"] = score
                    results.append(result)

            # SeÅ™azenÃ­ podle skÃ³re
            results.sort(key=lambda x: x["search_score"], reverse=True)
            return results[:limit]

        except Exception as e:
            logging.error(f"âŒ Chyba pÅ™i vyhledÃ¡vÃ¡nÃ­: {e}")
            return []

    async def get_documents_by_source(self, source: str) -> List[Dict[str, Any]]:
        """VrÃ¡tÃ­ vÅ¡echny dokumenty z konkrÃ©tnÃ­ho zdroje"""
        try:
            results = []
            for doc_id, metadata in self.documents_index.items():
                if metadata.get("source") == source:
                    doc = await self.get_document(doc_id)
                    if doc:
                        results.append(doc)
            return results
        except Exception as e:
            logging.error(f"âŒ Chyba pÅ™i naÄÃ­tÃ¡nÃ­ dokumentÅ¯ ze zdroje {source}: {e}")
            return []

    async def get_recent_documents(self, limit: int = 10) -> List[Dict[str, Any]]:
        """VrÃ¡tÃ­ nejnovÄ›jÅ¡Ã­ dokumenty"""
        try:
            # SeÅ™azenÃ­ podle timestamp
            sorted_docs = sorted(
                self.documents_index.items(), key=lambda x: x[1].get("timestamp", ""), reverse=True
            )

            results = []
            for doc_id, _ in sorted_docs[:limit]:
                doc = await self.get_document(doc_id)
                if doc:
                    results.append(doc)

            return results
        except Exception as e:
            logging.error(f"âŒ Chyba pÅ™i naÄÃ­tÃ¡nÃ­ nejnovÄ›jÅ¡Ã­ch dokumentÅ¯: {e}")
            return []

    async def update_document_metadata(self, doc_id: str, updates: Dict[str, Any]) -> bool:
        """
        Aktualizuje metadata dokumentu

        Args:
            doc_id: ID dokumentu
            updates: Dictionary s aktualizacemi

        Returns:
            bool: True pÅ™i ÃºspÄ›chu
        """
        try:
            if doc_id not in self.documents_index:
                return False

            # Aktualizace metadat
            self.documents_index[doc_id].update(updates)

            # Persist changes
            await self._save_index()

            logging.info(f"ğŸ“ Metadata dokumentu {doc_id} aktualizovÃ¡na")
            return True

        except Exception as e:
            logging.error(f"âŒ Chyba pÅ™i aktualizaci metadat {doc_id}: {e}")
            return False

    async def delete_document(self, doc_id: str) -> bool:
        """SmaÅ¾e dokument"""
        try:
            if doc_id not in self.documents_index:
                return False

            # SmazÃ¡nÃ­ souboru
            content_file = self.storage_path / f"{doc_id}.txt"
            if content_file.exists():
                content_file.unlink()

            # OdstranÄ›nÃ­ z indexu
            del self.documents_index[doc_id]

            # Persist changes
            await self._save_index()

            logging.info(f"ğŸ—‘ï¸ Dokument {doc_id} smazÃ¡n")
            return True

        except Exception as e:
            logging.error(f"âŒ Chyba pÅ™i mazÃ¡nÃ­ dokumentu {doc_id}: {e}")
            return False

    def get_stats(self) -> Dict[str, Any]:
        """VrÃ¡tÃ­ statistiky document store"""
        try:
            total_docs = len(self.documents_index)
            total_size = 0
            sources = {}

            for metadata in self.documents_index.values():
                # Velikost
                total_size += metadata.get("content_length", 0)

                # Zdroje
                source = metadata.get("source", "unknown")
                sources[source] = sources.get(source, 0) + 1

            return {
                "total_documents": total_docs,
                "total_content_size": total_size,
                "sources": sources,
                "storage_path": str(self.storage_path),
                "avg_credibility": self._calculate_avg_credibility(),
            }
        except Exception as e:
            logging.error(f"âŒ Chyba pÅ™i zÃ­skÃ¡vÃ¡nÃ­ statistik: {e}")
            return {}

    def _calculate_hash(self, content: str) -> str:
        """VypoÄÃ­tÃ¡ hash obsahu"""
        return hashlib.md5(content.encode("utf-8")).hexdigest()

    def _calculate_avg_credibility(self) -> float:
        """VypoÄÃ­tÃ¡ prÅ¯mÄ›rnou dÅ¯vÄ›ryhodnost dokumentÅ¯"""
        if not self.documents_index:
            return 0.0

        total_credibility = sum(
            metadata.get("credibility_score", 0.0) for metadata in self.documents_index.values()
        )
        return total_credibility / len(self.documents_index)

    def _load_index(self):
        """NaÄte index z souboru"""
        try:
            if self.metadata_file.exists():
                with open(self.metadata_file, "r", encoding="utf-8") as f:
                    self.documents_index = json.load(f)
                logging.info(f"ğŸ“š NaÄten index s {len(self.documents_index)} dokumenty")
        except Exception as e:
            logging.warning(f"âš ï¸ Chyba pÅ™i naÄÃ­tÃ¡nÃ­ indexu: {e}")
            self.documents_index = {}

    async def _save_index(self):
        """UloÅ¾Ã­ index do souboru"""
        try:
            with open(self.metadata_file, "w", encoding="utf-8") as f:
                json.dump(self.documents_index, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logging.error(f"âŒ Chyba pÅ™i uklÃ¡dÃ¡nÃ­ indexu: {e}")

    async def cleanup_old_documents(self, days: int = 30) -> int:
        """
        VyÄistÃ­ starÃ© dokumenty

        Args:
            days: Dokumenty starÅ¡Ã­ neÅ¾ tento poÄet dnÃ­ budou smazÃ¡ny

        Returns:
            int: PoÄet smazanÃ½ch dokumentÅ¯
        """
        try:
            cutoff_date = datetime.now() - timedelta(days=days)
            deleted_count = 0

            to_delete = []
            for doc_id, metadata in self.documents_index.items():
                doc_timestamp = datetime.fromisoformat(metadata.get("timestamp", ""))
                if doc_timestamp < cutoff_date:
                    to_delete.append(doc_id)

            for doc_id in to_delete:
                if await self.delete_document(doc_id):
                    deleted_count += 1

            logging.info(f"ğŸ§¹ SmazÃ¡no {deleted_count} starÃ½ch dokumentÅ¯")
            return deleted_count

        except Exception as e:
            logging.error(f"âŒ Chyba pÅ™i ÄiÅ¡tÄ›nÃ­ dokumentÅ¯: {e}")
            return 0
