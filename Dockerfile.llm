FROM python:3.11-slim-bookworm

# Set working directory
WORKDIR /app

# Install system dependencies for ML inference
RUN apt-get update && apt-get install -y \
    curl \
    git \
    build-essential \
    cmake \
    libopenblas-dev \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Install LLM inference dependencies
RUN pip install --no-cache-dir \
    fastapi \
    uvicorn \
    transformers>=4.35.0 \
    torch>=2.0.0 \
    accelerate>=0.24.0 \
    bitsandbytes>=0.41.0 \
    # Apple MLX for M1 optimization (if available)
    mlx-lm>=0.0.6 \
    # Fallback: llama.cpp python bindings
    llama-cpp-python>=0.2.0

# Copy source code
COPY workers/ ./workers/
COPY src/ ./src/

# Create model directory
RUN mkdir -p /app/models

# Set environment variables
ENV PYTHONPATH=/app
ENV MODEL_NAME=mistral-7b-instruct
ENV API_PORT=8001

# Expose port
EXPOSE 8001

# Run LLM API service
CMD ["python", "-m", "workers.llm_worker"]
