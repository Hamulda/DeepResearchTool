#!/usr/bin/env python3
"""
Komplexn√≠ test pro f√°ze 3 a 4 DeepResearchTool
Testuje deep web crawling, autonomn√≠ agenta a bezpeƒçnostn√≠ opat≈ôen√≠

Author: Senior Python/MLOps Agent
"""

import asyncio
import json
import logging
import tempfile
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any

import pytest

# Import testovan√Ωch komponent
from src.deep_web.network_manager import NetworkManager, NetworkConfig, NetworkType
from src.scraping.stealth_engine import StealthEngine, StealthConfig
from src.security.osint_sandbox import OSINTSecuritySandbox, SecurityLevel
from workers.deep_web_crawler import DeepWebCrawler, CrawlerConfig, crawl_onion_sites
from src.core.agentic_loop import AgenticLoop, TaskType, TaskPriority, AgentTask
from src.core.intelligent_task_manager import IntelligentTaskManager, TaskExecutionStrategy
from src.synthesis.hierarchical_summarizer import create_m1_summarizer
from src.synthesis.credibility_assessor import CredibilityAssessor
from src.synthesis.correlation_engine import CorrelationEngine
from src.synthesis.deep_pattern_detector import DeepPatternDetector

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class Phase3and4TestSuite:
    """Komplexn√≠ testovac√≠ suite pro f√°ze 3 a 4"""
    
    def __init__(self):
        self.test_results = {}
        self.temp_dir = Path(tempfile.mkdtemp())
        self.start_time = time.time()
        
        # Konfigurace pro testy
        self.security_config = {
            "security": {
                "osint": {
                    "security_level": "medium",
                    "rate_limits": {
                        "requests_per_minute": 30,
                        "requests_per_hour": 500,
                        "concurrent_requests": 5
                    },
                    "rules": {
                        "whitelist": [
                            "domain:httpbin.org",
                            "domain:example.com",
                            "domain:test.local"
                        ],
                        "blacklist": [
                            "regex:.*malware.*",
                            "domain:malicious-site.com"
                        ]
                    }
                }
            },
            "audit_trail": str(self.temp_dir / "test_audit.jsonl")
        }
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """Spust√≠ v≈°echny testy f√°z√≠ 3 a 4"""
        logger.info("üöÄ Spou≈°t√≠m komplexn√≠ testy f√°z√≠ 3 a 4...")
        
        # F√°ze 3 testy
        await self.test_network_manager()
        await self.test_stealth_engine()
        await self.test_security_sandbox()
        await self.test_deep_web_crawler()
        
        # F√°ze 4 testy
        await self.test_intelligent_task_manager()
        await self.test_agentic_loop()
        await self.test_integration_scenario()
        
        # Generov√°n√≠ fin√°ln√≠ho reportu
        return self.generate_final_report()
    
    async def test_network_manager(self):
        """Test s√≠≈•ov√©ho mana≈æera (F√°ze 3.1)"""
        logger.info("üîç Testov√°n√≠ Network Manageru...")
        
        try:
            # Konfigurace pouze pro clearnet (bezpeƒçn√© testov√°n√≠)
            config = NetworkConfig(
                enable_clearnet=True,
                enable_tor=False,  # Vypnuto pro CI/CD
                enable_i2p=False,  # Vypnuto pro CI/CD
                preferred_networks=[NetworkType.CLEARNET],
                default_timeout=10
            )
            
            async with NetworkManager(config) as network_manager:
                # Test health check
                health = await network_manager.health_check()
                
                # Test HTTP request
                try:
                    response = await network_manager.get("http://httpbin.org/ip")
                    request_success = response.status == 200
                except Exception as e:
                    request_success = False
                    logger.warning(f"HTTP request failed: {e}")
                
                # Test s√≠≈•ov√Ωch statistik
                status = await network_manager.get_network_status()
                
                self.test_results['network_manager'] = {
                    'status': 'success',
                    'health_check': health,
                    'http_request_success': request_success,
                    'network_status': status,
                    'clearnet_available': health.get('clearnet', {}).get('healthy', False)
                }
                
        except Exception as e:
            self.test_results['network_manager'] = {
                'status': 'failed',
                'error': str(e)
            }
            logger.error(f"Network Manager test failed: {e}")
    
    async def test_stealth_engine(self):
        """Test stealth scrapingu (F√°ze 3.2)"""
        logger.info("ü•∑ Testov√°n√≠ Stealth Engine...")
        
        try:
            config = StealthConfig(
                user_agent_rotation=True,
                header_randomization=True,
                timing_randomization=False,  # Rychlej≈°√≠ testy
                min_delay=0.1,
                max_delay=0.2
            )
            
            engine = StealthEngine(config)
            
            # Test scrapingu bezpeƒçn√© str√°nky
            result = await engine.scrape_url("http://httpbin.org/html", use_browser=False)
            
            # Test detekce anti-bot opat≈ôen√≠
            mock_content = """
            <html>
                <body>
                    <h1>Test Page</h1>
                    <p>This is a test page for scraping.</p>
                </body>
            </html>
            """
            
            detection = engine.browser_manager.anti_detection.detect_anti_bot_measures(
                mock_content, "http://httpbin.org/html"
            )
            
            # Test statistik
            stats = engine.get_session_stats()
            
            await engine.cleanup()
            
            self.test_results['stealth_engine'] = {
                'status': 'success',
                'scraping_result': {
                    'success': result.get('success', False),
                    'content_length': len(result.get('content', '')),
                    'final_url': result.get('final_url', '')
                },
                'anti_bot_detection': detection,
                'session_stats': stats
            }
            
        except Exception as e:
            self.test_results['stealth_engine'] = {
                'status': 'failed',
                'error': str(e)
            }
            logger.error(f"Stealth Engine test failed: {e}")
    
    async def test_security_sandbox(self):
        """Test bezpeƒçnostn√≠ho sandboxu (F√°ze 4.3)"""
        logger.info("üõ°Ô∏è Testov√°n√≠ Security Sandbox...")
        
        try:
            sandbox = OSINTSecuritySandbox(self.security_config)
            
            # Test access permission
            test_urls = [
                ("http://httpbin.org/ip", "allowed"),
                ("http://malicious-site.com/malware", "blocked"),
                ("http://example.com/test", "allowed")
            ]
            
            access_results = {}
            for url, expected in test_urls:
                result, metadata = sandbox.check_access_permission(url)
                access_results[url] = {
                    'result': result.value,
                    'expected': expected,
                    'metadata': metadata,
                    'correct': result.value == expected
                }
            
            # Test content processing
            test_content = "Research data: email@example.com, password: secret123"
            processed_content, processing_metadata = sandbox.process_content(
                test_content, "http://example.com/test"
            )
            
            # Test security statistics
            stats = sandbox.get_security_statistics()
            
            self.test_results['security_sandbox'] = {
                'status': 'success',
                'access_control_tests': access_results,
                'content_processing': {
                    'original_length': len(test_content),
                    'processed_length': len(processed_content),
                    'safety_report': processing_metadata.get('safety_report', {}),
                    'pii_redacted': 'REDACTED' in processed_content
                },
                'statistics': stats
            }
            
        except Exception as e:
            self.test_results['security_sandbox'] = {
                'status': 'failed',
                'error': str(e)
            }
            logger.error(f"Security Sandbox test failed: {e}")
    
    async def test_deep_web_crawler(self):
        """Test deep web crawleru (F√°ze 3.3)"""
        logger.info("üï∑Ô∏è Testov√°n√≠ Deep Web Crawler...")
        
        try:
            # Konfigurace pro bezpeƒçn√© testov√°n√≠ (pouze clearnet)
            config = CrawlerConfig(
                max_depth=1,
                max_pages_per_domain=3,
                max_total_pages=5,
                crawl_delay=0.5,
                tor_identity_rotation_interval=999  # Vysok√© ƒç√≠slo pro testy
            )
            
            # Mock test - vytvo≈ô√≠me crawler ale nebudeme crawlovat .onion
            crawler = DeepWebCrawler(config)
            
            # Test z√°kladn√≠ funkcionality bez skuteƒçn√©ho crawlingu
            test_urls = ["http://httpbin.org/html"]
            
            # Simulace crawlingu (bez skuteƒçn√© inicializace Tor/I2P)
            mock_results = []
            for url in test_urls:
                if crawler._is_valid_url(url.replace('http', 'https').replace('.org', '.onion')):
                    mock_results.append({
                        'url': url,
                        'title': 'Test Page',
                        'links_found': 3,
                        'depth': 0
                    })
            
            # Test utility funkc√≠
            domain = crawler._extract_domain("http://example.onion/test")
            is_valid = crawler._is_valid_url("http://test.onion/page")
            
            self.test_results['deep_web_crawler'] = {
                'status': 'success',
                'config_validation': {
                    'max_depth': config.max_depth,
                    'max_pages': config.max_total_pages,
                    'crawl_delay': config.crawl_delay
                },
                'utility_functions': {
                    'domain_extraction': domain == 'example.onion',
                    'url_validation': is_valid,
                },
                'mock_crawl_results': mock_results,
                'crawler_initialized': True
            }
            
        except Exception as e:
            self.test_results['deep_web_crawler'] = {
                'status': 'failed',
                'error': str(e)
            }
            logger.error(f"Deep Web Crawler test failed: {e}")
    
    async def test_intelligent_task_manager(self):
        """Test inteligentn√≠ho task manageru (F√°ze 4.1)"""
        logger.info("üß† Testov√°n√≠ Intelligent Task Manager...")
        
        try:
            # Mock credibility assessor
            class MockCredibilityAssessor:
                async def assess_content(self, content, url):
                    return 0.8
            
            credibility_assessor = MockCredibilityAssessor()
            task_manager = IntelligentTaskManager(credibility_assessor)
            
            # Vytvo≈ôen√≠ testovac√≠ch √∫kol≈Ø
            test_tasks = []
            for i in range(5):
                task = AgentTask(
                    id=f"task_{i}",
                    task_type=TaskType.ANALYZE,
                    priority=TaskPriority.MEDIUM,
                    parameters={"test_param": f"value_{i}"},
                    created_at=datetime.now(),
                    credibility_score=0.7 + (i * 0.05)
                )
                test_tasks.append(task)
                await task_manager.add_task_with_intelligence(task)
            
            # Test optim√°ln√≠ho po≈ôad√≠
            optimal_order = task_manager.get_optimal_execution_order(test_tasks)
            
            # Test alokace zdroj≈Ø
            resource_allocation = await task_manager.optimize_resource_allocation(test_tasks)
            
            # Test r≈Øzn√Ωch strategi√≠
            strategies_tested = {}
            for strategy in TaskExecutionStrategy:
                task_manager.strategy = strategy
                order = task_manager.get_optimal_execution_order(test_tasks)
                strategies_tested[strategy.value] = len(order)
            
            # Test uƒçen√≠ a adaptace
            task_manager.record_execution_result("task_0", True, 5.0, {"quality": "high"})
            task_manager.record_execution_result("task_1", False, 10.0, {})
            
            insights = task_manager.get_learning_insights()
            task_manager.adapt_strategy()
            
            self.test_results['intelligent_task_manager'] = {
                'status': 'success',
                'task_graph_nodes': len(task_manager.task_graph.nodes),
                'optimal_order_length': len(optimal_order),
                'resource_allocation': resource_allocation,
                'strategies_tested': strategies_tested,
                'learning_insights': insights,
                'current_strategy': task_manager.strategy.value
            }
            
        except Exception as e:
            self.test_results['intelligent_task_manager'] = {
                'status': 'failed',
                'error': str(e)
            }
            logger.error(f"Intelligent Task Manager test failed: {e}")
    
    async def test_agentic_loop(self):
        """Test autonomn√≠ho agenta (F√°ze 4.1)"""
        logger.info("ü§ñ Testov√°n√≠ Agentic Loop...")
        
        try:
            # Mock komponenty
            class MockDocumentStore:
                async def store_document(self, doc):
                    return f"doc_{hash(str(doc)) % 1000}"
            
            class MockWebScraper:
                async def scrape_page(self, url):
                    return f"Content from {url}"
            
            class MockCredibilityAssessor:
                async def assess_content(self, content, url):
                    return 0.75
            
            class MockCorrelationEngine:
                async def analyze_text(self, text):
                    return {"entities": [{"id": "entity_1", "type": "person"}]}
                
                async def find_related_entities(self, entity_id):
                    return [{"id": "related_1", "relation": "associated"}]
            
            class MockPatternDetector:
                async def analyze_text(self, text):
                    return {"artifacts": [{"pattern": "test_pattern", "confidence": 0.8}]}
            
            # Inicializace komponent
            document_store = MockDocumentStore()
            credibility_assessor = MockCredibilityAssessor()
            correlation_engine = MockCorrelationEngine()
            pattern_detector = MockPatternDetector()
            web_scraper = MockWebScraper()
            
            # Vytvo≈ôen√≠ agentic loop
            agent = AgenticLoop(
                document_store=document_store,
                credibility_assessor=credibility_assessor,
                correlation_engine=correlation_engine,
                pattern_detector=pattern_detector,
                web_scraper=web_scraper,
                max_iterations=3,
                min_credibility_threshold=0.5
            )
            
            # Test kr√°tk√©ho v√Ωzkumn√©ho cyklu
            initial_query = "Test research query about artificial intelligence"
            test_urls = ["http://httpbin.org/html"]
            
            # Spu≈°tƒõn√≠ kr√°tk√©ho cyklu
            results = await agent.start_research_cycle(initial_query, test_urls)
            
            # Test aktu√°ln√≠ho stavu
            status = agent.get_current_status()
            
            self.test_results['agentic_loop'] = {
                'status': 'success',
                'research_results': {
                    'iterations_completed': results['research_summary']['iterations_completed'],
                    'total_tasks_executed': results['research_summary']['total_tasks_executed'],
                    'average_credibility': results['research_summary']['average_credibility'],
                    'key_discoveries_count': len(results['key_discoveries'])
                },
                'agent_status': status,
                'final_recommendations': results.get('recommendations', [])
            }
            
        except Exception as e:
            self.test_results['agentic_loop'] = {
                'status': 'failed',
                'error': str(e)
            }
            logger.error(f"Agentic Loop test failed: {e}")
    
    async def test_integration_scenario(self):
        """Test kompletn√≠ho integraƒçn√≠ho sc√©n√°≈ôe"""
        logger.info("üîó Testov√°n√≠ integraƒçn√≠ho sc√©n√°≈ôe...")
        
        try:
            # Sc√©n√°≈ô: Bezpeƒçn√Ω v√Ωzkum s autonomn√≠m agentem
            scenario_results = {}
            
            # 1. Bezpeƒçnostn√≠ kontrola
            sandbox = OSINTSecuritySandbox(self.security_config)
            test_url = "http://httpbin.org/ip"
            
            access_result, metadata = sandbox.check_access_permission(test_url)
            scenario_results['security_check'] = {
                'url': test_url,
                'allowed': access_result.value == 'allowed',
                'metadata': metadata
            }
            
            # 2. Stealth scraping (pokud povoleno)
            if access_result.value == 'allowed':
                engine = StealthEngine(StealthConfig(
                    timing_randomization=False,
                    min_delay=0.1,
                    max_delay=0.1
                ))
                
                scrape_result = await engine.scrape_url(test_url, use_browser=False)
                
                # 3. Bezpeƒçn√© zpracov√°n√≠ obsahu
                if scrape_result.get('success'):
                    processed_content, processing_metadata = sandbox.process_content(
                        scrape_result['content'], test_url
                    )
                    
                    scenario_results['content_processing'] = {
                        'scraping_success': True,
                        'content_length': len(scrape_result['content']),
                        'processed_length': len(processed_content),
                        'safety_score': processing_metadata['safety_report']['score']
                    }
                
                await engine.cleanup()
            
            # 4. Anal√Ωza bezpeƒçnostn√≠ch metrik
            security_stats = sandbox.get_security_statistics()
            scenario_results['security_metrics'] = {
                'total_attempts': security_stats.get('total_access_attempts', 0),
                'success_rate': security_stats.get('success_rate', 0),
                'block_rate': security_stats.get('block_rate', 0)
            }
            
            self.test_results['integration_scenario'] = {
                'status': 'success',
                'scenario_results': scenario_results,
                'workflow_completed': True
            }
            
        except Exception as e:
            self.test_results['integration_scenario'] = {
                'status': 'failed',
                'error': str(e)
            }
            logger.error(f"Integration scenario test failed: {e}")
    
    def generate_final_report(self) -> Dict[str, Any]:
        """Generuje fin√°ln√≠ report z test≈Ø"""
        total_time = time.time() - self.start_time
        
        # Poƒç√≠t√°n√≠ √∫spƒõ≈°n√Ωch test≈Ø
        successful_tests = sum(1 for result in self.test_results.values() 
                             if result.get('status') == 'success')
        total_tests = len(self.test_results)
        
        # Identifikace probl√©mov√Ωch oblast√≠
        failed_tests = [name for name, result in self.test_results.items() 
                       if result.get('status') == 'failed']
        
        # Hodnocen√≠ pokryt√≠ funkcionalit
        phase3_coverage = self._assess_phase3_coverage()
        phase4_coverage = self._assess_phase4_coverage()
        
        report = {
            'test_summary': {
                'total_tests': total_tests,
                'successful_tests': successful_tests,
                'failed_tests': len(failed_tests),
                'success_rate': successful_tests / total_tests if total_tests > 0 else 0,
                'total_runtime_seconds': total_time
            },
            'phase_coverage': {
                'phase_3_deep_web': phase3_coverage,
                'phase_4_autonomous_agent': phase4_coverage
            },
            'detailed_results': self.test_results,
            'failed_components': failed_tests,
            'recommendations': self._generate_recommendations(),
            'next_steps': self._generate_next_steps(),
            'metadata': {
                'test_timestamp': datetime.now().isoformat(),
                'test_environment': 'development',
                'temp_directory': str(self.temp_dir)
            }
        }
        
        return report
    
    def _assess_phase3_coverage(self) -> Dict[str, Any]:
        """Hodnot√≠ pokryt√≠ f√°ze 3"""
        return {
            'network_manager': self.test_results.get('network_manager', {}).get('status') == 'success',
            'stealth_engine': self.test_results.get('stealth_engine', {}).get('status') == 'success',
            'deep_web_crawler': self.test_results.get('deep_web_crawler', {}).get('status') == 'success',
            'security_sandbox': self.test_results.get('security_sandbox', {}).get('status') == 'success',
            'overall_coverage': sum([
                self.test_results.get('network_manager', {}).get('status') == 'success',
                self.test_results.get('stealth_engine', {}).get('status') == 'success',
                self.test_results.get('deep_web_crawler', {}).get('status') == 'success',
                self.test_results.get('security_sandbox', {}).get('status') == 'success'
            ]) / 4
        }
    
    def _assess_phase4_coverage(self) -> Dict[str, Any]:
        """Hodnot√≠ pokryt√≠ f√°ze 4"""
        return {
            'intelligent_task_manager': self.test_results.get('intelligent_task_manager', {}).get('status') == 'success',
            'agentic_loop': self.test_results.get('agentic_loop', {}).get('status') == 'success',
            'integration_scenario': self.test_results.get('integration_scenario', {}).get('status') == 'success',
            'overall_coverage': sum([
                self.test_results.get('intelligent_task_manager', {}).get('status') == 'success',
                self.test_results.get('agentic_loop', {}).get('status') == 'success',
                self.test_results.get('integration_scenario', {}).get('status') == 'success'
            ]) / 3
        }
    
    def _generate_recommendations(self) -> List[str]:
        """Generuje doporuƒçen√≠ na z√°kladƒõ v√Ωsledk≈Ø test≈Ø"""
        recommendations = []
        
        if 'network_manager' in self.test_results:
            if self.test_results['network_manager'].get('status') == 'failed':
                recommendations.append("Opravit konfiguraci Network Manageru pro stabiln√≠ s√≠≈•ov√© spojen√≠")
        
        if 'stealth_engine' in self.test_results:
            if self.test_results['stealth_engine'].get('status') == 'success':
                recommendations.append("Stealth Engine funguje spr√°vnƒõ - lze zaƒç√≠t s testov√°n√≠m na re√°ln√Ωch str√°nk√°ch")
        
        if 'security_sandbox' in self.test_results:
            if self.test_results['security_sandbox'].get('status') == 'success':
                recommendations.append("Bezpeƒçnostn√≠ sandbox je funkƒçn√≠ - syst√©m je p≈ôipraven pro OSINT operace")
        
        if 'agentic_loop' in self.test_results:
            if self.test_results['agentic_loop'].get('status') == 'success':
                recommendations.append("Autonomn√≠ agent funguje - lze testovat na komplexnƒõj≈°√≠ch sc√©n√°≈ô√≠ch")
        
        return recommendations
    
    def _generate_next_steps(self) -> List[str]:
        """Generuje dal≈°√≠ kroky na z√°kladƒõ v√Ωsledk≈Ø"""
        next_steps = []
        
        # Anal√Ωza √∫spƒõ≈°nosti
        success_rate = self.test_results.get('test_summary', {}).get('success_rate', 0)
        
        if success_rate >= 0.8:
            next_steps.extend([
                "Syst√©m je p≈ôipraven pro produkƒçn√≠ nasazen√≠",
                "Spustit performance testy s vƒõt≈°√≠mi datov√Ωmi sadami",
                "Implementovat monitoring a alerting pro produkƒçn√≠ prost≈ôed√≠"
            ])
        elif success_rate >= 0.6:
            next_steps.extend([
                "Opravit identifikovan√© probl√©my p≈ôed produkƒçn√≠m nasazen√≠m",
                "Roz≈°√≠≈ôit testovac√≠ pokryt√≠ pro problematick√© oblasti",
                "Optimalizovat konfiguraci komponent"
            ])
        else:
            next_steps.extend([
                "Prov√©st detailn√≠ anal√Ωzu selh√°n√≠ komponent",
                "Refaktorovat problematick√© moduly",
                "Pos√≠lit testovac√≠ suite p≈ôed dal≈°√≠m testov√°n√≠m"
            ])
        
        return next_steps


async def main():
    """Hlavn√≠ funkce pro spu≈°tƒõn√≠ test≈Ø"""
    print("üß™ Spou≈°t√≠m komplexn√≠ testy f√°z√≠ 3 a 4 DeepResearchTool...")
    print("=" * 60)
    
    test_suite = Phase3and4TestSuite()
    
    try:
        # Spu≈°tƒõn√≠ v≈°ech test≈Ø
        final_report = await test_suite.run_all_tests()
        
        # V√Ωpis v√Ωsledk≈Ø
        print("\nüìä FIN√ÅLN√ç REPORT")
        print("=" * 60)
        
        summary = final_report['test_summary']
        print(f"‚úÖ √öspƒõ≈°n√© testy: {summary['successful_tests']}/{summary['total_tests']}")
        print(f"üìà √öspƒõ≈°nost: {summary['success_rate']:.1%}")
        print(f"‚è±Ô∏è Celkov√Ω ƒças: {summary['total_runtime_seconds']:.1f}s")
        
        print(f"\nüéØ POKRYT√ç F√ÅZ√ç")
        print("-" * 30)
        phase3 = final_report['phase_coverage']['phase_3_deep_web']
        phase4 = final_report['phase_coverage']['phase_4_autonomous_agent']
        print(f"F√°ze 3 (Deep Web): {phase3['overall_coverage']:.1%}")
        print(f"F√°ze 4 (Autonomn√≠ Agent): {phase4['overall_coverage']:.1%}")
        
        if final_report['failed_components']:
            print(f"\n‚ùå SELH√ÅN√ç")
            print("-" * 30)
            for component in final_report['failed_components']:
                error = final_report['detailed_results'][component].get('error', 'Nezn√°m√° chyba')
                print(f"‚Ä¢ {component}: {error}")
        
        if final_report['recommendations']:
            print(f"\nüí° DOPORUƒåEN√ç")
            print("-" * 30)
            for i, rec in enumerate(final_report['recommendations'], 1):
                print(f"{i}. {rec}")
        
        print(f"\nüîÑ DAL≈†√ç KROKY")
        print("-" * 30)
        for i, step in enumerate(final_report['next_steps'], 1):
            print(f"{i}. {step}")
        
        # Ulo≈æen√≠ detailn√≠ho reportu
        report_file = test_suite.temp_dir / "phase3_4_test_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nüìÑ Detailn√≠ report ulo≈æen: {report_file}")
        
        # V√Ωstupn√≠ k√≥d podle √∫spƒõ≈°nosti
        if summary['success_rate'] >= 0.8:
            print("\nüéâ Testy probƒõhly √∫spƒõ≈°nƒõ! Syst√©m je p≈ôipraven k pou≈æit√≠.")
            return 0
        elif summary['success_rate'] >= 0.6:
            print("\n‚ö†Ô∏è Testy ƒç√°steƒçnƒõ √∫spƒõ≈°n√©. Pot≈ôebn√© drobn√© opravy.")
            return 1
        else:
            print("\nüö® Testy selhaly. Nutn√© v√Ωznamn√© opravy.")
            return 2
            
    except Exception as e:
        print(f"\nüí• Kritick√° chyba p≈ôi testov√°n√≠: {e}")
        logger.exception("Critical test failure")
        return 3


if __name__ == "__main__":
    import sys
    exit_code = asyncio.run(main())
    sys.exit(exit_code)